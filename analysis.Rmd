---
title: "Responses to Virtual Environments - Preliminary Analysis"
author: Tiernan J. Cahill
output: html_notebook
---

```{r setup, include=FALSE}
library(dplyr)
library(knitr)
library(ggplot2)
library(rstatix)

study_data <- readRDS("data/congruity_data.rds")
```

# Diagnostics
Before we beginning our analysis, we check to see if the measured variables of interest are nearly-normally distributed, so we can make decisions about what sort of models will be appropriate. We can begin with a quick visual inspection using histograms.

```{r diag}
# ITQ (Control variable)
ggplot(study_data, aes(x = ITQ)) +
  geom_histogram(binwidth = 5, fill = "#0AA57F", alpha = 0.8) +
  labs(x="Immersive Tendencies", y = "Count") 

# Spatial situation (Response variable)
ggplot(study_data, aes(x = SSM)) +
  geom_histogram(binwidth = 0.5, fill = "#5964B3", alpha = 0.8) +
  facet_grid(rows = vars(condition)) +
  labs(x = "Spatial Situation", y = "Count")

# Self-presence (Response variable)
ggplot(study_data, aes(x = SPSL)) +
  geom_histogram(binwidth = 0.5, fill = "#3439C8", alpha = 0.8) +
  facet_grid(rows = vars(condition)) +
  labs(x="Self-Presence", y = "Count")

# Suspension of disbelief (Response variable)
ggplot(study_data, aes(x = SoD)) +
  geom_histogram(binwidth = 0.5, fill = "#004DC3", alpha = 0.8)+
  facet_grid(rows = vars(condition)) +
  labs(x="Suspension of Disbelief", y = "Count")

# Simulator sickness (Response variable)
ggplot(study_data, aes(x = sim_sick)) +
  geom_histogram(binwidth = 5, fill = "#490415", alpha = 0.8) +
  labs(x="Simulator Sickness", y = "Count")
```

From the visualization, it appears that most of the variables of interest allow us the assumption of near-normality, with the exception of simulator sickness, which is skewed left (since many more participants experience a few minor symptoms than many major symptoms). We will deal with this later. We can confirm this with a Shapiro-Wilk test.

```{r sw-test, warning=FALSE}
shapiro.test(study_data$sim_sick)
```

# Hypothesis Tests
## Presence
We are interested in whether measures of presence vary significantly between control and breach conditions in each of the three experiments. This is a one-sided test, since we can reasonably hypothesize that presence will be lower in the breach condition.

### Sensory Congruity
First, looking at the experiment in which sensory congruity was breached, we can visualize the presence measures reported by the two groups (in the control and breach conditions).

```{r sensory-viz}
sensory_data <- study_data %>%
  filter(condition == "SENSORY")

# Spatial situation
sensory_data %>%
  ggplot(aes(x = control, y = SSM)) +
  geom_boxplot(fill = "#5964B3", alpha = 0.8) + 
  xlab("Condition") + ylab("Spatial Situation")

# Self-presence / Self-location
sensory_data %>%
  ggplot(aes(x = control, y = SPSL)) +
  geom_boxplot(fill = "#3439C8", alpha = 0.8) + 
  xlab("Condition") + ylab("Self-Presence / Self-Location")

# Suspension of disbelief
sensory_data %>%
  ggplot(aes(x = control, y = SoD)) +
  geom_boxplot(fill = "#004DC3", alpha = 0.8) + 
  xlab("Condition") + ylab("Suspension of Disbelief")
```

Next, we can run some statistical tests, starting with simple t-tests.

```{r sensory-tests}
bartlett.test(SSM ~ control, sensory_data)
t.test(SSM ~ control, sensory_data, alternative = "greater", var.equal = TRUE)

bartlett.test(SPSL ~ control, sensory_data)
t.test(SPSL ~ control, sensory_data, alternative = "greater", var.equal = TRUE)

bartlett.test(SoD ~ control, sensory_data)
t.test(SoD ~ control, sensory_data, alternative = "greater", var.equal = TRUE)
```

It looks like we can assume equal variances based on the results of Bartlett's tests, but that the differences between groups aren't significant. Let's try again, controlling for individual differences in immersive tendencies using an ANCOVA.

```{r sensory-tests-control}
sensory_data %>%
  anova_test(SSM ~ ITQ + control, type = 3)

sensory_data %>%
  anova_test(SPSL ~ ITQ + control, type = 3)

sensory_data %>%
  anova_test(SoD ~ ITQ + control, type = 3)
```

It still doesn't look like there's much of a significant difference between the experimental groups when controlling for immersive tendencies.

### Environment Congruity
We repeat the above procedure for the second experiment, where environmental congruity was breached.

```{r enviro-viz, warnings = FALSE}
enviro_data <- study_data %>%
  filter(condition == "ENVIRONMENTAL")

# Spatial situation
enviro_data %>%
  ggplot(aes(x = control, y = SSM)) +
  geom_boxplot(fill = "#5964B3", alpha = 0.8) + 
  xlab("Condition") + ylab("Spatial Situation")

# Self-presence / Self-location
enviro_data %>%
  ggplot(aes(x = control, y = SPSL)) +
  geom_boxplot(fill = "#3439C8", alpha = 0.8) + 
  xlab("Condition") + ylab("Self-Presence / Self-Location")

# Suspension of disbelief
enviro_data %>%
  ggplot(aes(x = control, y = SoD)) +
  geom_boxplot(fill = "#004DC3", alpha = 0.8) + 
  xlab("Condition") + ylab("Suspension of Disbelief")
```

```{r enviro-tests}
bartlett.test(SSM ~ control, enviro_data)
t.test(SSM ~ control, enviro_data, alternative = "greater", var.equal = TRUE)

bartlett.test(SPSL ~ control, enviro_data)
t.test(SPSL ~ control, enviro_data, alternative = "greater", var.equal = TRUE)

bartlett.test(SoD ~ control, enviro_data)
t.test(SoD ~ control, enviro_data, alternative = "greater", var.equal = TRUE)
```

It looks like there might be a significant difference in suspension of disbelief, based on the T test. Let's see what happens when we control for immersive tendencies.

```{r enviro-tests-control}
enviro_data %>%
  anova_test(SSM ~ ITQ + control, type = 3)

enviro_data %>%
  anova_test(SPSL ~ ITQ + control, type = 3)

enviro_data %>%
  anova_test(SoD ~ ITQ + control, type = 3)
```

In this case, because the test is one-sided, a p-value < 0.1 is considered significant, which remains the case for Suspension of Disbelief in the environmnental breach condition, even when controlling for immersive tendencies.


### Thematic
Finally, let's repeat all of the above steps for the thematic breach condition.

```{r thematic-viz, warnings = FALSE}
thematic_data <- study_data %>%
  filter(condition == "THEMATIC")

# Spatial situation
thematic_data %>%
  ggplot(aes(x = control, y = SSM)) +
  geom_boxplot(fill = "#5964B3", alpha = 0.8) + 
  xlab("Condition") + ylab("Spatial Situation")

# Self-presence / Self-location
thematic_data %>%
  ggplot(aes(x = control, y = SPSL)) +
  geom_boxplot(fill = "#3439C8", alpha = 0.8) + 
  xlab("Condition") + ylab("Self-Presence / Self-Location")

# Suspension of disbelief
thematic_data %>%
  ggplot(aes(x = control, y = SoD)) +
  geom_boxplot(fill = "#004DC3", alpha = 0.8) + 
  xlab("Condition") + ylab("Suspension of Disbelief")
```

```{r thematic-tests}
bartlett.test(SSM ~ control, thematic_data)
t.test(SSM ~ control, thematic_data, alternative = "greater", var.equal = TRUE)

bartlett.test(SPSL ~ control, thematic_data)
t.test(SPSL ~ control, thematic_data, alternative = "greater", var.equal = TRUE)

bartlett.test(SoD ~ control, thematic_data)
t.test(SoD ~ control, thematic_data, alternative = "greater", var.equal = TRUE)
```

It appears that self-presence / self-location is significantly lower in the thematic breach condition. Let's now control for immersive tendencies, as before.

```{r thematic-tests-control}
thematic_data %>%
  anova_test(SSM ~ ITQ + control, type = 3)

thematic_data %>%
  anova_test(SPSL ~ ITQ + control, type = 3)

thematic_data %>%
  anova_test(SoD ~ ITQ + control, type = 3)
```

The previous findings are mirrored in the ANCOVA test.